{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are performing linear regression and finding the optimal parameters (weights and bias) that best fit the input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we are doing the manual approch, without using any prebuild libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 3],\n",
       "       [6, 4],\n",
       "       [7, 6],\n",
       "       [9, 8]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.random.seed(5)\n",
    "#this is the input x \n",
    "# we can see that there 2 features ( in form of 2 coloumns)\n",
    "x=np.array([[5,3],[6,4],[7,6],[9,8]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [4],\n",
       "       [7],\n",
       "       [8]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this the output varible\n",
    "\n",
    "y=np.array([2,4,7,8])\n",
    "y=y.reshape(-1,1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "indf=pd.DataFrame()\n",
    "\n",
    "indf['X1']=x[:,0]\n",
    "indf['X2']=x[:,1]\n",
    "indf['Target Var']=y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how our input and output variables looks like in tablular form , for now to learn the concepts were are using less data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have 2 features x1 and x2 and one target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>Target Var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2  Target Var\n",
       "0   5   3           2\n",
       "1   6   4           4\n",
       "2   7   6           7\n",
       "3   9   8           8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRG(x,y,lr,epoch):\n",
    "    m=x.shape[0]#number of trainning examples\n",
    "    nx=x.shape[1]#number of features\n",
    "    lr=0.01#learning rate\n",
    "\n",
    "    w=np.zeros(shape=(nx,1))#initialing weights\n",
    "    b=0\n",
    "    cost_history=[]\n",
    "    for i in range(epoch):\n",
    "        \n",
    "        yhat=np.dot(x,w)+b #prediction , order of dot is important , it should be x,w only\n",
    "        error=yhat-y #error from the og y\n",
    "        cost=np.dot(error.T,error)/(2*m) #this is standard formula for calculating and minimize the MSE in linear regression.\n",
    "        \n",
    "        dw=np.dot(x.T,error)/m #change in cost due to change in w (weights)\n",
    "        db= np.sum(error)/m #change in cost due to change in b (bias)\n",
    "        \n",
    "        #these both updates the old value of w and b with new updated values\n",
    "        w=w-(lr*dw)\n",
    "        b=b-(lr*db)\n",
    "        \n",
    "        cost_history.append(cost) #we are storing the loss or error or mse in the list , so that later we check if the cost is minized by plotting it \n",
    "        \n",
    "    return w,b # we are returning the final parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=LRG(x,y,0.01,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first value in X is the optimum value of the bias and the second value is array with 2 elements which are the optimum weights for both the features (w1 and w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.32492419],\n",
       "        [ 1.46913743]]),\n",
       " -0.2842943865158093)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make similar model using prebuild ML libraries , like we are using Sklearn below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum Bias:[3.6] \n",
      "Optimum Weights:[[-1.7  2.5]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.linear_model as lm\n",
    "lr = lm.LinearRegression()\n",
    "lr.fit(x,y)\n",
    "print(f'Optimum Bias:{lr.intercept_} \\nOptimum Weights:{lr.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using similar approch, we can build a model for logistic regression also by chaning the cost function in this code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
